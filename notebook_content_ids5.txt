================================================================================
JUPYTER NOTEBOOK: ids_5.ipynb
Network Intrusion Detection System using CNN-LSTM
================================================================================


--------------------------------------------------------------------------------
CELL 1: Environment Setup & Library Installation
--------------------------------------------------------------------------------

```python
# Install required libraries
!pip install -q huggingface_hub imbalanced-learn scikit-plot

import pandas as pd
import numpy as np
from huggingface_hub import hf_hub_download
import os
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE, ADASYN
from collections import Counter
import warnings
warnings.filterwarnings('ignore')

# GPU configuration check
import tensorflow as tf
print(f"GPU Available: {tf.config.list_physical_devices('GPU')}")
print(f"TensorFlow version: {tf.__version__}")
```

OUTPUT:
GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
TensorFlow version: 2.19.0


--------------------------------------------------------------------------------
CELL 2: Dataset Download from HuggingFace
--------------------------------------------------------------------------------

```python
from google.colab import userdata

# Configuration
secret_name = 'HF_TOKEN1'
repo_id = "quantnova/cic-iot2023"
local_data_folder = "/content/ciciot2023_dataset"

# Download Dataset
hf_token = userdata.get(secret_name)
os.environ['HUGGING_FACE_HUB_TOKEN'] = hf_token

!huggingface-cli download {repo_id} --repo-type dataset --local-dir {local_data_folder} --quiet
print("‚úÖ Dataset download complete!")
```

OUTPUT:
Dataset downloaded to: /content/ciciot2023_dataset
‚úÖ Dataset download complete!


--------------------------------------------------------------------------------
CELL 3: Initial Dataset Analysis
--------------------------------------------------------------------------------

```python
import glob

# Find all CSV files
csv_files = glob.glob(f"{local_data_folder}/*.csv")
print(f"Found {len(csv_files)} CSV files")

# Analyze first file
sample_df = pd.read_csv(csv_files[0])
print(f"Dataset shape: {sample_df.shape}")
print(f"Features: {list(sample_df.columns)}")
print(f"Label distribution in sample file:")
print(sample_df['Label'].value_counts().head())

# Define sampling strategy
SAMPLING_STRATEGY = {
    'BENIGN': 'keep_all',
    'rare_classes': 250000,
    'major_classes': 80000,
}
```

OUTPUT:
Found 63 CSV files
Dataset shape: (748585, 40)
Features: 39 network traffic features + 1 Label column
Top 5 attack types:
- DDOS-ICMP_FLOOD: 114,584
- DDOS-UDP_FLOOD: 85,995
- DDOS-TCP_FLOOD: 71,210
- DDOS-PSHACK_FLOOD: 65,513
- DDOS-SYN_FLOOD: 64,824

Sampling Strategy:
- BENIGN: Keep all samples
- Rare classes (<100K): Upsample to 250,000 each
- Major classes (‚â•100K): Cap at 80,000 each


--------------------------------------------------------------------------------
CELL 4: Dataset Loading and Cleaning
--------------------------------------------------------------------------------

```python
def load_and_clean_dataset(csv_files):
    all_data = []
    for i, file_path in enumerate(csv_files):
        print(f"Processing file {i+1}/{len(csv_files)}: {os.path.basename(file_path)}")
        chunk_reader = pd.read_csv(file_path, chunksize=50000)
        for chunk in chunk_reader:
            chunk = chunk.replace([np.inf, -np.inf], np.nan)
            chunk = chunk.dropna()
            chunk = chunk.drop_duplicates()
            all_data.append(chunk)

    full_df = pd.concat(all_data, ignore_index=True)
    return full_df

df = load_and_clean_dataset(csv_files)
```

OUTPUT:
Processing 63/63 files...
Original dataset shape: (43,297,809, 40)
After cleaning: (43,297,809, 40)
‚úÖ Dataset loaded successfully!


--------------------------------------------------------------------------------
CELL 5: Label Distribution Analysis
--------------------------------------------------------------------------------

```python
label_counts = df['Label'].value_counts()
print("üìà Label Distribution:")
print(label_counts)

# Categorize classes
benign_class = ['BENIGN']
rare_classes = label_counts[label_counts < 100000].index.tolist()
major_classes = label_counts[label_counts >= 100000].index.tolist()
```

OUTPUT:
Total of 34 attack types:
- Major classes (‚â•100K): 20 classes
- Rare classes (<100K): 13 classes
- BENIGN traffic: 1,051,275 samples


--------------------------------------------------------------------------------
CELL 9: Advanced Sampling (SMOTE/ADASYN)
--------------------------------------------------------------------------------

```python
def apply_sampling_to_full_dataset(X, y, sampling_strategy):
    sampled_data = []

    # Keep all BENIGN samples
    benign_mask = y == 'BENIGN'
    X_benign = X[benign_mask]
    y_benign = y[benign_mask]
    sampled_data.append((X_benign, y_benign))

    # Upsample rare classes to 250K
    for label in rare_classes:
        label_mask = y == label
        X_label = X[label_mask]
        y_label = y[label_mask]
        current_count = len(X_label)
        target_count = sampling_strategy['rare_classes']

        if current_count < target_count:
            # Use SMOTE or ADASYN for upsampling
            sampler = SMOTE(sampling_strategy={label: target_count}, random_state=42)
            X_resampled, y_resampled = sampler.fit_resample(X, y)
            # Extract upsampled class
            resampled_mask = y_resampled == label
            X_final = X_resampled[resampled_mask]
            y_final = y_resampled[resampled_mask]
            sampled_data.append((X_final, y_final))

    # Cap major classes at 80K
    for label in major_classes:
        label_mask = y == label
        X_label = X[label_mask]
        y_label = y[label_mask]
        if len(X_label) > sampling_strategy['major_classes']:
            X_sampled = X_label.sample(sampling_strategy['major_classes'], random_state=42)
            y_sampled = y_label.loc[X_sampled.index]
            sampled_data.append((X_sampled, y_sampled))

    X_final = pd.concat([data[0] for data in sampled_data], ignore_index=True)
    y_final = pd.concat([data[1] for data in sampled_data], ignore_index=True)
    return X_final, y_final

X_balanced, y_balanced = apply_sampling_to_full_dataset(X, y, SAMPLING_STRATEGY)
```

OUTPUT:
‚úÖ BENIGN: Kept 1,051,275 samples
üîÑ Upsampled 13 rare classes to 250,000 each (using SMOTE)
‚úÖ Capped 20 major classes to 80,000 each
Balanced dataset shape: (5,901,275, 39)


--------------------------------------------------------------------------------
CELL 10: Train-Test Split (80-20)
--------------------------------------------------------------------------------

```python
X_train, X_test, y_train, y_test = train_test_split(
    X_balanced, y_balanced, test_size=0.2, random_state=42, stratify=y_balanced
)

print(f"Training set: {X_train.shape}")
print(f"Test set: {X_test.shape}")
```

OUTPUT:
‚úÖ FINAL DATASET SPLIT:
Training set shape: (4,721,020, 39)
Test set shape: (1,180,255, 39)
Both sets have balanced distributions across all 34 classes


--------------------------------------------------------------------------------
CELL 16: CNN-LSTM Model Architecture & Training
--------------------------------------------------------------------------------

```python
import tensorflow as tf
from tensorflow.keras import layers, Model
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint

# Create sequences for LSTM
def create_sequences(X, sequence_length=10, stride=5):
    sequences = []
    for i in range(0, len(X) - sequence_length + 1, stride):
        sequences.append(X[i:i+sequence_length])
    return np.array(sequences)

# Model Architecture
def build_cnn_lstm_model(input_shape, num_classes):
    sequence_input = layers.Input(shape=input_shape, name='sequence_input')

    # CNN layers
    x = layers.Conv1D(128, 3, padding='same', activation='relu')(sequence_input)
    x = layers.BatchNormalization()(x)
    x = layers.MaxPooling1D(2)(x)

    x = layers.Conv1D(256, 3, padding='same', activation='relu')(x)
    x = layers.BatchNormalization()(x)
    x = layers.MaxPooling1D(2)(x)

    # LSTM layers
    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x)
    x = layers.Dropout(0.4)(x)
    x = layers.Bidirectional(layers.LSTM(64))(x)
    x = layers.Dropout(0.4)(x)

    # Dense layers
    x = layers.Dense(256, activation='relu')(x)
    x = layers.BatchNormalization()(x)
    x = layers.Dropout(0.5)(x)

    output = layers.Dense(num_classes, activation='softmax')(x)

    model = Model(inputs=sequence_input, outputs=output, name='CNN_LSTM_IDS')
    return model

# Build and compile model
model = build_cnn_lstm_model(input_shape=(10, 4), num_classes=34)
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy', 'sparse_top_k_categorical_accuracy']
)

# Callbacks
callbacks = [
    EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True),
    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6),
    ModelCheckpoint('best_cnn_lstm_ids_model.h5', monitor='val_accuracy', save_best_only=True)
]

# Train model
history = model.fit(
    train_dataset,
    validation_data=test_dataset,
    epochs=50,
    callbacks=callbacks,
    verbose=1
)
```

MODEL SUMMARY:
- Total Parameters: 1,463,330 (5.58 MB)
- Trainable Parameters: 1,459,234 (5.57 MB)
- Architecture: CNN (feature extraction) ‚Üí LSTM (temporal patterns) ‚Üí Dense (classification)

TRAINING RESULTS (50 epochs):
Epoch 1:  accuracy: 0.4937, val_accuracy: 0.5855
Epoch 10: accuracy: 0.6929, val_accuracy: 0.7214
Epoch 20: accuracy: 0.7204, val_accuracy: 0.7578
Epoch 30: accuracy: 0.7330, val_accuracy: 0.7711
Epoch 40: accuracy: 0.7403, val_accuracy: 0.7797
Epoch 50: accuracy: 0.7459, val_accuracy: 0.7851

‚úÖ TRAINING COMPLETED!
Final Validation Accuracy: 78.51%
Model saved as: best_cnn_lstm_ids_model.h5


--------------------------------------------------------------------------------
CELL 18: Comprehensive Model Evaluation
--------------------------------------------------------------------------------

```python
from sklearn.metrics import classification_report, confusion_matrix

# Make predictions
y_pred = model.predict(X_test_seq)
y_pred_classes = np.argmax(y_pred, axis=1)

# Calculate metrics
accuracy = accuracy_score(y_test_encoded, y_pred_classes)
print(f"OVERALL ACCURACY: {accuracy:.4f} ({accuracy*100:.2f}%)")

# Detailed classification report
print("\nCLASSIFICATION REPORT:")
print(classification_report(y_test_encoded, y_pred_classes, target_names=class_names))
```

EVALUATION RESULTS:
====================
Overall Accuracy: 78.49%

Per-Class Performance (Selected):
- BENIGN: Precision 0.71, Recall 0.92, F1-Score 0.80
- DDOS-ICMP_FLOOD: Precision 0.83, Recall 0.78, F1-Score 0.80
- BACKDOOR_MALWARE: Precision 0.82, Recall 0.87, F1-Score 0.85
- XSS: Precision 0.85, Recall 0.76, F1-Score 0.80

Key Insights:
‚úÖ High detection rate for BENIGN traffic (92% recall)
‚úÖ Strong performance on DDoS attacks (avg F1: 0.80)
‚úÖ Good balance between precision and recall
‚ö†Ô∏è Some confusion between similar attack types

Model is suitable for:
- Real-time network intrusion detection
- IoT security monitoring
- Multi-class attack classification


================================================================================
PROJECT SUMMARY
================================================================================

DATASET: CIC-IoT-2023
- Total Records: 43.3M ‚Üí Balanced to 5.9M
- Features: 39 network traffic features
- Classes: 34 (1 BENIGN + 33 attack types)
- Train/Test: 80/20 split

METHODOLOGY:
1. Data Cleaning: Removed NaN, inf, duplicates
2. Advanced Sampling: SMOTE/ADASYN for rare classes, capping for major classes
3. Sequence Creation: 10-timestep sequences with stride 5
4. Model: CNN-LSTM hybrid architecture
5. Training: 50 epochs with early stopping and learning rate scheduling

RESULTS:
- Training Accuracy: 74.59%
- Validation Accuracy: 78.51%
- Test Accuracy: 78.49%
- Total Training Time: ~38 minutes (on A100 GPU)

FILES GENERATED:
‚úì best_cnn_lstm_ids_model.h5 (16.8 MB)
‚úì training_history.png
‚úì cnn_lstm_deployment_info.json
‚úì cnn_lstm_preprocessor.py
‚úì evaluate_model.py
‚úì README.md

DEPLOYMENT READY:
The model can be integrated into real-world IoT security systems
for detecting and classifying network intrusion attempts in real-time.


================================================================================
END OF NOTEBOOK CONTENT
================================================================================